{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIKgUVp0/qXjZSqA1oqt/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoant1/explorasi_hard_skill_DE_python_programming/blob/main/tokopedia_web_scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Instalasi Library Python yang Dibutuhkan ---\n",
        "# Selenium: Untuk otomatisasi browser dan web scraping\n",
        "# Pandas: Untuk manipulasi dan analisis data dalam bentuk DataFrame\n",
        "# Matplotlib & Seaborn: Untuk membuat visualisasi (grafik)\n",
        "# BeautifulSoup4: Meskipun tidak menjadi fokus utama dengan Selenium di sini,\n",
        "#                  tetap baik untuk diinstal sebagai alat bantu parsing HTML\n",
        "!pip install selenium pandas matplotlib seaborn beautifulsoup4\n",
        "\n",
        "# --- Instalasi Chrome Browser dan ChromeDriver (Otomatis untuk Colab) ---\n",
        "# apt-get: Perintah untuk menginstal paket di sistem Linux (yang digunakan Colab)\n",
        "!apt-get update # Memperbarui daftar paket yang tersedia\n",
        "!apt-get install -y chromium-browser # Menginstal browser Chromium (versi open-source dari Chrome)\n",
        "!pip install chromedriver-autoinstaller # Menginstal library Python untuk mendownload ChromeDriver yang cocok secara otomatis\n",
        "\n",
        "# --- Import Library Python yang Akan Digunakan ---\n",
        "# Ini harus diimpor SETELAH instalasi selesai\n",
        "import chromedriver_autoinstaller # Untuk instalasi ChromeDriver otomatis\n",
        "from selenium import webdriver # Modul utama Selenium\n",
        "from selenium.webdriver.chrome.service import Service # Untuk konfigurasi service ChromeDriver\n",
        "from selenium.webdriver.common.by import By # Untuk menentukan cara mencari elemen (misal: berdasarkan CSS Selector, ID, dll.)\n",
        "from selenium.webdriver.support.ui import WebDriverWait # Untuk menunggu elemen muncul secara dinamis\n",
        "from selenium.webdriver.support import expected_conditions as EC # Kondisi yang diharapkan saat menunggu\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException # Untuk menangani error spesifik dari Selenium\n",
        "import time # Untuk memberikan jeda waktu\n",
        "import re # Untuk ekspresi reguler (membersihkan teks)\n",
        "import pandas as pd # Untuk DataFrame\n",
        "import matplotlib.pyplot as plt # Untuk plotting grafik dasar\n",
        "import seaborn as sns # Untuk visualisasi statistik yang lebih indah\n",
        "\n",
        "# --- Konfigurasi dan Inisialisasi WebDriver ---\n",
        "# chromedriver_autoinstaller akan secara otomatis mencari dan menginstal ChromeDriver yang sesuai\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# Opsi untuk menjalankan Chrome dalam mode 'headless' (tanpa antarmuka grafis)\n",
        "# Ini penting karena Google Colab adalah lingkungan server tanpa GUI\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless') # Mode headless: browser berjalan di latar belakang\n",
        "options.add_argument('--no-sandbox') # Diperlukan untuk menjalankan Chrome di lingkungan virtual seperti Colab\n",
        "options.add_argument('--disable-dev-shm-usage') # Mencegah masalah memori di lingkungan Colab\n",
        "\n",
        "# Inisialisasi WebDriver\n",
        "try:\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    print(\"STATUS: WebDriver berhasil diinisialisasi untuk Google Colab (headless).\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Terjadi kesalahan saat menginisialisasi WebDriver: {e}\")\n",
        "    print(\"Pastikan instalasi Chrome Browser dan ChromeDriver berhasil di atas, dan opsi Chrome sudah benar.\")\n",
        "    print(\"Jika masalah berlanjut, coba restart runtime Colab (Runtime -> Restart runtime) dan jalankan lagi semua sel dari awal.\")\n",
        "    exit() # Keluar dari program jika WebDriver tidak bisa diinisialisasi\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wd198jAO5MQ",
        "outputId": "ad6a5593-b9ed-4b1f-b341-f1e9323e663b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.9)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from chromedriver-autoinstaller) (24.2)\n",
            "STATUS: WebDriver berhasil diinisialisasi untuk Google Colab (headless).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Konfigurasi URL dan Variabel Scraping ---\n",
        "# Ganti 'laptop' dengan kata kunci pencarian lain jika diinginkan\n",
        "base_url = \"https://www.tokopedia.com/search?st=product&q=laptop\"\n",
        "all_product_data = [] # List untuk menyimpan semua data produk yang berhasil di-scrape\n",
        "num_pages_to_scrape = 3 # Jumlah halaman yang ingin kita scrape\n",
        "\n",
        "print(f\"\\n--- Memulai Proses Web Scraping dari {num_pages_to_scrape} Halaman Tokopedia ---\")\n",
        "\n",
        "# --- Loop untuk Melakukan Scraping pada Setiap Halaman ---\n",
        "for page_num in range(1, num_pages_to_scrape + 1):\n",
        "    url = f\"{base_url}&page={page_num}\" # Membangun URL untuk halaman yang sedang diproses\n",
        "    driver.get(url) # Membuka URL di browser Selenium\n",
        "    print(f\"\\nSTATUS: Mengakses halaman: {url}\")\n",
        "\n",
        "    # --- Penanganan Konten Dinamis (Menunggu & Scroll) ---\n",
        "    try:\n",
        "        # Tunggu hingga elemen kartu produk (product-card) muncul di halaman\n",
        "        # Ini penting agar JavaScript memiliki waktu untuk memuat konten\n",
        "        print(f\"DEBUG: Menunggu elemen produk muncul di halaman {page_num}...\")\n",
        "        WebDriverWait(driver, 20).until( # Tunggu maksimal 20 detik\n",
        "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '[data-testid=\"product-card\"]'))\n",
        "        )\n",
        "        print(f\"DEBUG: Elemen 'product-card' berhasil ditemukan.\")\n",
        "\n",
        "        # Lakukan scroll ke bawah berulang kali untuk memuat semua produk (lazy loading)\n",
        "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        while True:\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(2) # Beri jeda 2 detik agar konten baru sempat dimuat\n",
        "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                print(f\"DEBUG: Scroll selesai di halaman {page_num}. Tidak ada lagi konten baru yang dimuat.\")\n",
        "                break # Berhenti jika tinggi halaman tidak bertambah (berarti semua konten sudah dimuat)\n",
        "            last_height = new_height\n",
        "        print(f\"STATUS: Konten halaman {page_num} berhasil dimuat sepenuhnya (setelah scroll).\")\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(f\"ERROR: Timeout! Produk tidak ditemukan di halaman {page_num} setelah 20 detik.\")\n",
        "        print(f\"DEBUG: Panjang source code halaman saat timeout: {len(driver.page_source)} karakter.\")\n",
        "        # Simpan screenshot untuk debugging visual jika terjadi timeout\n",
        "        driver.save_screenshot(f'/content/timeout_page_{page_num}.png')\n",
        "        print(f\"DEBUG: Screenshot halaman {page_num} disimpan sebagai /content/timeout_page_{page_num}.png\")\n",
        "        continue # Lanjutkan ke halaman berikutnya jika halaman ini gagal dimuat\n",
        "\n",
        "    # --- Ekstraksi Data Produk dari Halaman Saat Ini ---\n",
        "    products = driver.find_elements(By.CSS_SELECTOR, '[data-testid=\"product-card\"]')\n",
        "    print(f\"DEBUG: Ditemukan total {len(products)} elemen produk di halaman {page_num} untuk diekstrak.\")\n",
        "\n",
        "    if not products:\n",
        "        print(f\"WARNING: Tidak ada elemen produk yang valid ditemukan di halaman {page_num} untuk diekstrak. Mungkin selector salah atau situs memblokir akses.\")\n",
        "        continue # Lanjut ke halaman berikutnya\n",
        "\n",
        "    for product in products:\n",
        "        try:\n",
        "            # Ekstraksi Nama Produk\n",
        "            name_element = product.find_element(By.CSS_SELECTOR, '[data-testid=\"lblPDPDetailProductName\"]')\n",
        "            name = name_element.text.strip() if name_element else \"N/A\"\n",
        "\n",
        "            # Ekstraksi Harga Produk\n",
        "            price_element = product.find_element(By.CSS_SELECTOR, '[data-testid=\"lblPDPDetailProductPrice\"]')\n",
        "            price_text = price_element.text.strip() if price_element else \"N/A\"\n",
        "            # Membersihkan teks harga (menghilangkan 'Rp' dan '.') lalu mengkonversi ke float\n",
        "            price = float(re.sub(r'[Rp.]', '', price_text)) if price_text != \"N/A\" else 0.0\n",
        "\n",
        "            # Ekstraksi Rating Produk\n",
        "            rating_element = product.find_elements(By.CSS_SELECTOR, '[data-testid=\"rating\"]')\n",
        "            rating = 0.0\n",
        "            if rating_element:\n",
        "                # Contoh: aria-label=\"Rating 4.5 dari 5\" -> kita ambil angka 4.5\n",
        "                match = re.search(r'Rating (\\d+\\.?\\d*)', rating_element[0].get_attribute('aria-label'))\n",
        "                if match:\n",
        "                    rating = float(match.group(1))\n",
        "\n",
        "            # Ekstraksi Jumlah Ulasan Produk (mungkin ada dua selector yang berbeda)\n",
        "            reviews = 0\n",
        "            reviews_element_1 = product.find_elements(By.CSS_SELECTOR, '.css-1bidzud span.css-1rn6k3f')\n",
        "            if reviews_element_1 and \"Ulasan\" in reviews_element_1[0].text:\n",
        "                match = re.search(r'(\\d+)\\s*Ulasan', reviews_element_1[0].text)\n",
        "                if match:\n",
        "                    reviews = int(match.group(1))\n",
        "            else: # Coba selector alternatif jika yang pertama tidak ditemukan\n",
        "                reviews_element_2 = product.find_elements(By.CSS_SELECTOR, '[data-testid=\"lblCardRatingProductCount\"]')\n",
        "                if reviews_element_2:\n",
        "                    match = re.search(r'(\\d+)', reviews_element_2[0].text)\n",
        "                    if match:\n",
        "                        reviews = int(match.group(1))\n",
        "\n",
        "            # Tambahkan data produk ke list\n",
        "            all_product_data.append({\n",
        "                'Nama Produk': name,\n",
        "                'Harga': price,\n",
        "                'Rating': rating,\n",
        "                'Jumlah Ulasan': reviews\n",
        "            })\n",
        "\n",
        "        except NoSuchElementException:\n",
        "            # DEBUG: print(f\"DEBUG: Beberapa elemen tidak ditemukan untuk satu produk di halaman {page_num}. Melewati produk ini.\")\n",
        "            continue # Lanjutkan ke produk berikutnya jika ada elemen yang tidak ditemukan\n",
        "        except Exception as e:\n",
        "            # DEBUG: print(f\"DEBUG: Error umum saat mengekstrak data produk di halaman {page_num}: {e}. Melewati produk ini.\")\n",
        "            continue # Lanjutkan ke produk berikutnya jika ada error lainnya\n",
        "\n",
        "    print(f\"STATUS: Selesai mengekstrak data dari halaman {page_num}.\")\n",
        "    print(f\"STATUS: Total produk terkumpul hingga saat ini: {len(all_product_data)}\")\n",
        "    time.sleep(2) # Beri jeda 2 detik antar halaman untuk mengurangi risiko deteksi bot\n",
        "\n",
        "# Tutup browser Selenium setelah semua proses scraping selesai\n",
        "driver.quit()\n",
        "print(\"\\n--- Proses Scraping Selesai. Browser Ditutup. ---\")\n",
        "\n",
        "# --- Langkah 3: Tampilkan Detail dalam Pandas DataFrame dan Visualisasi ---\n",
        "print(\"\\n--- Memulai Analisis dan Visualisasi Data ---\")\n",
        "\n",
        "# Buat DataFrame dari data yang terkumpul\n",
        "df = pd.DataFrame(all_product_data)\n",
        "\n",
        "# --- Pemeriksaan dan Ringkasan DataFrame ---\n",
        "if not df.empty:\n",
        "    print(\"\\n--- DataFrame Berhasil Dibuat ---\")\n",
        "    print(\"5 Baris Pertama Data:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\nInformasi Umum DataFrame (Tipe Data, Non-Null Count):\")\n",
        "    df.info()\n",
        "\n",
        "    print(\"\\nStatistik Deskriptif (Rata-rata, Min, Max, dll. untuk kolom numerik):\")\n",
        "    print(df.describe())\n",
        "\n",
        "    # --- Pembersihan Tipe Data untuk Visualisasi ---\n",
        "    # Pastikan kolom numerik memiliki tipe data yang benar, 'coerce' akan mengubah error menjadi NaN\n",
        "    df['Harga'] = pd.to_numeric(df['Harga'], errors='coerce')\n",
        "    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
        "    df['Jumlah Ulasan'] = pd.to_numeric(df['Jumlah Ulasan'], errors='coerce')\n",
        "\n",
        "    # Hapus baris yang memiliki nilai kosong (NaN) di kolom kunci setelah konversi\n",
        "    # Ini penting agar visualisasi tidak error karena data tidak valid\n",
        "    df.dropna(subset=['Harga', 'Rating', 'Jumlah Ulasan'], inplace=True)\n",
        "\n",
        "    if df.empty: # Cek lagi setelah dropna\n",
        "        print(\"\\nWARNING: DataFrame kosong setelah proses pembersihan data. Tidak ada data yang valid untuk divisualisasikan.\")\n",
        "    else:\n",
        "        print(\"\\n--- Memulai Pembuatan Visualisasi ---\")\n",
        "\n",
        "        # 1. Distribusi Harga Produk\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        sns.histplot(df['Harga'], bins=50, kde=True, color='skyblue')\n",
        "        plt.title('Distribusi Harga Produk Laptop di Tokopedia', fontsize=16)\n",
        "        plt.xlabel('Harga (Rp)', fontsize=12)\n",
        "        plt.ylabel('Frekuensi', fontsize=12)\n",
        "        plt.ticklabel_format(style='plain', axis='x') # Mematikan notasi ilmiah pada sumbu X\n",
        "        plt.grid(axis='y', alpha=0.75)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # 2. Distribusi Rating Produk\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.countplot(x=df['Rating'].round(1), data=df, palette='viridis', order=sorted(df['Rating'].round(1).unique())) # Mengelompokkan rating ke 1 desimal\n",
        "        plt.title('Distribusi Rating Produk Laptop di Tokopedia', fontsize=16)\n",
        "        plt.xlabel('Rating (Skala 0-5)', fontsize=12)\n",
        "        plt.ylabel('Jumlah Produk', fontsize=12)\n",
        "        plt.grid(axis='y', alpha=0.75)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # 3. Hubungan antara Harga dan Rating (dengan ukuran titik berdasarkan Jumlah Ulasan)\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        # Hue dan size berdasarkan Jumlah Ulasan untuk menambah informasi visual\n",
        "        sns.scatterplot(x='Harga', y='Rating', data=df, alpha=0.7, hue='Jumlah Ulasan', size='Jumlah Ulasan', sizes=(20, 400), palette='coolwarm')\n",
        "        plt.title('Hubungan Harga dan Rating Produk Laptop (Ukuran Titik = Jumlah Ulasan)', fontsize=16)\n",
        "        plt.xlabel('Harga (Rp)', fontsize=12)\n",
        "        plt.ylabel('Rating', fontsize=12)\n",
        "        plt.ticklabel_format(style='plain', axis='x')\n",
        "        plt.grid(True, alpha=0.75)\n",
        "        plt.legend(title='Jumlah Ulasan', bbox_to_anchor=(1.05, 1), loc='upper left') # Pindahkan legenda agar tidak menutupi plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # 4. Top 10 Produk dengan Ulasan Terbanyak (Jika ada data ulasan)\n",
        "        if not df.empty and 'Jumlah Ulasan' in df.columns and df['Jumlah Ulasan'].sum() > 0:\n",
        "            top_reviews_products = df.sort_values(by='Jumlah Ulasan', ascending=False).head(10)\n",
        "            if not top_reviews_products.empty:\n",
        "                plt.figure(figsize=(12, 8))\n",
        "                sns.barplot(x='Jumlah Ulasan', y='Nama Produk', data=top_reviews_products, palette='rocket')\n",
        "                plt.title('10 Produk Laptop dengan Ulasan Terbanyak', fontsize=16)\n",
        "                plt.xlabel('Jumlah Ulasan', fontsize=12)\n",
        "                plt.ylabel('Nama Produk', fontsize=12)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"DEBUG: Setelah sorting, top_reviews_products kosong.\")\n",
        "        else:\n",
        "            print(\"INFO: Tidak ada data ulasan yang cukup untuk menampilkan Top 10 produk.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nERROR: DataFrame kosong. Tidak ada data yang berhasil di-scrape untuk ditampilkan atau divisualisasikan.\")\n",
        "    print(\"Silakan periksa output di atas untuk pesan ERROR/WARNING saat proses scraping untuk menemukan penyebabnya.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6wCRxX5PL2w",
        "outputId": "3cd583bd-e4eb-413a-8f05-1dfab97ff58c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Memulai Proses Web Scraping dari 3 Halaman Tokopedia ---\n",
            "\n",
            "STATUS: Mengakses halaman: https://www.tokopedia.com/search?st=product&q=laptop&page=1\n",
            "DEBUG: Menunggu elemen produk muncul di halaman 1...\n",
            "ERROR: Timeout! Produk tidak ditemukan di halaman 1 setelah 20 detik.\n",
            "DEBUG: Panjang source code halaman saat timeout: 180829 karakter.\n",
            "DEBUG: Screenshot halaman 1 disimpan sebagai /content/timeout_page_1.png\n",
            "\n",
            "STATUS: Mengakses halaman: https://www.tokopedia.com/search?st=product&q=laptop&page=2\n",
            "DEBUG: Menunggu elemen produk muncul di halaman 2...\n",
            "ERROR: Timeout! Produk tidak ditemukan di halaman 2 setelah 20 detik.\n",
            "DEBUG: Panjang source code halaman saat timeout: 180829 karakter.\n",
            "DEBUG: Screenshot halaman 2 disimpan sebagai /content/timeout_page_2.png\n",
            "\n",
            "STATUS: Mengakses halaman: https://www.tokopedia.com/search?st=product&q=laptop&page=3\n",
            "DEBUG: Menunggu elemen produk muncul di halaman 3...\n",
            "ERROR: Timeout! Produk tidak ditemukan di halaman 3 setelah 20 detik.\n",
            "DEBUG: Panjang source code halaman saat timeout: 180829 karakter.\n",
            "DEBUG: Screenshot halaman 3 disimpan sebagai /content/timeout_page_3.png\n",
            "\n",
            "--- Proses Scraping Selesai. Browser Ditutup. ---\n",
            "\n",
            "--- Memulai Analisis dan Visualisasi Data ---\n",
            "\n",
            "ERROR: DataFrame kosong. Tidak ada data yang berhasil di-scrape untuk ditampilkan atau divisualisasikan.\n",
            "Silakan periksa output di atas untuk pesan ERROR/WARNING saat proses scraping untuk menemukan penyebabnya.\n"
          ]
        }
      ]
    }
  ]
}